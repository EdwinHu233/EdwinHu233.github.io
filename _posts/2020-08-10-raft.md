---
layout: post
title: "论文笔记：Raft"
---

* TOC
{:toc}

## Raft 要解决的问题

很多种分布式系统的设计都依赖于单个 master 和若干个 slave ，
例如 MapReduce , GFS 等。

之所以采用单个 master 作为决策者，
主要是为了避免 "split brain" 现象。
例如，
假设我们设置了两个服务器 $ s  _  1, s _ 2 $ 作为决策者，
客户端的请求需要同时送给 $ s _ 1, s _ 2 $ ，
以保证二者的一致性。
但是如果由于网络原因，
客户端 $ c _ 1 $ 只能访问 $ s _ 1 $ ，
而 $ c _ 2 $ 则可以正常访问 $ s _ 1, s _ 2 $ 的话。
当 $ c _ 1 $ 向 $ s _ 1 $ 成功发送请求后，
$ s _ 1 $ 的状态被更新了，
而 $ s _ 2 $ 的状态则没有。
因此，$ c _ 2 $ 就会发现 $ s _ 1, s _ 2 $ 的不一致。
这种 "split brain" 现象的根源在于，
无法辨别“网络故障”和“服务器崩溃”这两种情况，
毕竟在发送请求的一方看来，
症状都是一样的：
发送了请求，而没有得到回应。

不过，这种以单个服务器作为决策者的设计也有缺点。
虽然单个服务器出现故障的概率比较低（相对于多个服务器而言），
但一旦发生故障，
就会导致整个系统不能正常工作。
我们希望有一种共识算法，
既能避免 "split brain" 现象，
又能提高容错率。

Raft 就是这样一个共识算法，
它将多个服务器对外抽象为了单一的决策者，
以保证一致性和容错性。

为了避免 split brain ，
Raft 的一条核心设计理念是 "majority vote" 。
一个 Raft 系统包含 **奇数** 个服务器（一个典型的数字为 5），
任何有效的状态改变都需要得到大部分服务器（"majority"）的同意。
所谓的 "majority" 是一个逻辑上的服务器集合，
包含了当前数量上占大部分的、能正常工作且互相通信的所有服务器。
majority 是随时动态变化的，
有的服务器会由于自身崩溃或网络原因退出 majority ，
也有的服务器在退出 majority 后恢复正常、重新加入 majority 。
不论 majority 中的服务器怎样变动，
变动前的 majority 一定与变动后的 majority 存在非空交集（鸽巢原理），
而这个交集中的服务器就可以提供某些信息，
以维持新的 majority 的一致性。

## Raft 概述

Raft 中，
每个服务器都有一套相同的状态机，
对于相同的输入，状态机会产生相同的输出。
状态机的所有输入都保存在一个 log 中，
状态机从 log 中按顺序取出指令，依次执行。
因此，只要保证 log 的一致性，就能保证整个系统的一致性。

每个服务器的身份可能是 leader/candidate/follower 中的一种。
正常情况下，集群中恰有一个 leader ，其余都是 follower 。
而在 leader election 时，会发生 follower -> candidate 和 candidate -> leader/follower 的转变。

客户端在与 Raft 系统通信时，
只能向 leader 发起请求，
然后由 leader 回应。
请求中包含由状态机执行的指令，
回应中包含状态机执行的结果。

leader 接受到请求后：
- 将指令放入自己的 log 中
- 向 followers 发送 RPC
- 等待 majority （包括自己）成功地在 log 中复制这条指令
    - 被 majority 复制的 log entry 被称为 "committed log entry"
    - majority 不会忘记 committed log entries ，并保证它们的一致性
    - 一条 committed log entry 之前的所有 entries 都是 committed 的
- leader 在状态机上执行此命令，并向客户端返回结果
- leader 在之后的 RPC 中，告知其他服务器这条 log entry 已经 committed
- 其他服务器在状态机上执行此命令

不同服务器的 log 可能不同。
有的会缺少部分 entries ，
有的会持有多余的 entries 。
但 Raft 保证：
- 所有服务器的 log 会最终相同
- 服务器只会执行 log 中已经稳定的 entries

Raft 算法的设计主要包含两个方面：
- 选举 leader
- 保证 log 相同

Raft 算法中包含两个 RPC ：
- `RequestVote`: 在选举时由 candidate 发起
- `AppendEntries`: 由 leader 发起，用于复制 log ，同时也作为心跳机制

## 选举 leader

### “任期” 的概念

Raft 将时间被划分为若干个任期，
每个任期由一个单调递增的整数标识。
- 每个任期内最多有一个 leader （也可能没有）
- 其他服务器只会服从最新的 leader
    - 每个服务器会记录自认为的当前任期 `currentTerm`
    - 这个数字会在通讯时彼此交换
    - 最新的 leader （以及服从它的服务器）一定会有最大的 `currentTerm`

每个任期的开始都会有一个选举阶段，
如果成功选举出一个 leader ，则这个任期正常持续；
否则这个任期会结束，并开始新的任期。
如下图所示：

![leader election](/asset/raft/leader-election.png)

### 选举是怎样发起的

每个服务器会根据自己观察到的情况，
决定是否发起选举。具体来说：
- 当自己在 "election timeout" 这么长的时间里，
没有收到来自 leader 的通信时
- 它就会增加自己的 `currentTerm` ，
并从 follower 变为 candidate ，
试图收集投票（向其他服务器发送 `RequestVote` ）
    - 如果 candidate 在一个新的 "election timeout" 内收集到大部分服务器的选票，就会变为 leader
    - 原本的 leader 如果是可达的并收到了 `RequestVote` ，就会在回应中表示拒绝，并附上 `currentTerm` ；然后 candidate 会回退到 follower 状态
- 注意：
    - 这种机制可能会导致不必要的选举（以一定的性能为代价，保证安全性）
    - 原本的 leader 可能还活着，并自认为还是 leader（后面会讨论）

### leader 的权威性

如何保证每个任期内最多只有一个 leader 呢？
- candidate 必须从大部分服务器获得选票
- 一个任期内，每个服务器只能最多投一次票
    - candidate 会给自己投票
    - 非 candidate 会给第一个遇到的 candidate 投票（有一些限制条件，后面会讲）

当有新的 leader 产生时，服务器们是怎样得知的？
- leader 自己会看到大部分服务器发来的选票
- leader 会给其他服务器发送 `AppendEntries` RPC ，其中包含了 `currentTerm`
    - 这个 `currentTerm` 是当前全局最大的
    - 这种心跳机制会压制其他服务器，不让它们发起选举

### 选举失败

之前说过，
一个任期内可能没有 leader ，
这可能由两个原因造成：
- 对于 candidate 来说，大部分服务器不可达
- 同时有多个 candidate 发起选举，导致没有任何 candidate 得到大部分投票

如果 candidate 在 "election timeout" 内没有收集到大部分服务器的选票，
也没有被新的 leader 压制，
它就会得知选举失败了，
然后再次递增 `currentTerm` 并发起选举。

这两种导致选举失败的原因中，
前者是难以避免的，
但后者可以最大程度的被规避。
具体来说，每个服务器会有自己的 "election timeout" ，
这个值是随机初始化的。
因此，以下两种情况发生的概率很小：
- 同时有多个 follower 转变为 candidate ，并发起选举
- 选举失败后，同时有多个 candidate 重新发起选举

### 新 leader 与老 leader 并存的情况

如果新 leader 当选后，
老 leader 还活着，并自认为是 leader 呢？
之前说过，如果老 leader 是可达的，并收到了 `RequestVote` 请求，
会压制 candidate 的当选。
所以，这种情况可能由两种原因造成：
- 老 leader 没有看到 `RequestVote` 请求
- 老 leader 在一个 minority network partition 中
（一定是 minority 而不是 majority ，否则新 leader 不可能得到 majority 的投票）

不过，这种情况并不会有什么危害。
新 leader 在当选后会向其他服务器发送 `AppendEntries` 作为心跳，
使得 majority 更新自身的 `currentTerm`
（如果 majority 未能更新 `currentTerm` 的话，
说明新 leader 不能压制 majority ，
自然会有比它更新的 leader 当选）。
因此，majority 中的服务器即使收到旧 leader 的通信，
也不会服从旧 leader 。

{% comment %} 每个服务器会保存一个数字 `currentTerm` ，表示自认为所在的 term 。 {% endcomment %}
{% comment %} 这个数字会在通讯时彼此交换，如果一个服务器发现自己的 `currentTerm` 比通讯对方的小，就说明自己的 `currentTerm` 过时。 {% endcomment %}

{% comment %} - 任何服务器发现自己的 `currentTerm` 过时，都要更新自己的 `currentTerm` {% endcomment %}
{% comment %} - candidate/leader 如果发现自己的 `currentTerm` 过时，就会回退到 follower 状态。 {% endcomment %}
{% comment %} - 任何服务器发现对方的 `currentTerm` 过时，都会拒绝对方的 request {% endcomment %}


{% comment %} 服务器会尽量并行地发送 RPC ，如果有的 RPC 没有 response ，则会重新发送。 {% endcomment %}

{% comment %} ### Leader Election {% endcomment %}

{% comment %} 服务器启动时，身份为 follower 。 {% endcomment %}
{% comment %} 如果 follower 不断收到来自 leader/candidate 的 RPC ，那么就会始终保持在 follower 状态。 {% endcomment %}
{% comment %} 同时，leader 也会向 follower 们发送“空的”（不附加任何 log entry ） 的 `AppendEntries` 作为 heartbeat ，确保自身地位。 {% endcomment %}

{% comment %} 如果一个 follower 在一定时间（称为 election timeout ）之内没有收到 RPC 的话，就认为 leader 出现问题。 {% endcomment %}
{% comment %} 此时，follower 会将自己的 `currentTerm` 加1，并转变为 candidate 状态。 {% endcomment %}
{% comment %} 之后，这个服务器会给自己投一票，并向其他服务器发起 `RequestVote` 。 {% endcomment %}
{% comment %} 一个服务器在一个 term 内，只能给最多一个服务器投票（原则上是给第一个向自己请求的服务器投票，但 [Safety](#Safety) 一节中会引入限制条件） {% endcomment %}

{% comment %} Leader election 的过程中，candidate 可能会收到自称 leader 的服务器发来的 `AppendEntries` 。 {% endcomment %}
{% comment %} 这时 candidate 会根据 `currentTerm` 采取不同行动： {% endcomment %}
{% comment %} - 如果自己的 `currentTerm` > 对方的 `currentTerm` ，则认为对方是过气 leader ，从而拒绝对方的 RPC 请求 {% endcomment %}
{% comment %} - 否则，认为对方是当前合法的 leader ，从而回退到 follower 状态 {% endcomment %}

{% comment %} 在一个 candidate 进行 leader election 时，会发生以下三种情况： {% endcomment %}
{% comment %} - 自己当选 {% endcomment %}
{% comment %} - 其他 candidate 当选 {% endcomment %}
{% comment %} - 没有任何 candidate 当选（有多个 candidate 获得了相同的最高投票数）。 {% endcomment %}
{% comment %} 具体来说，在 leader election 刚开始时，candidate 会重启 election timeout ，如果直到超时也没有任何 candidate 当选， {% endcomment %}
{% comment %} 就会结束当前 term ，并开始新 term ，重新选举。 {% endcomment %}

{% comment %} 可以发现，election timeout 是一个很关键的因素。Follower 转变为 candidate 会用到这个值，candidate 重新发起选举也会用到这个值。 {% endcomment %}
{% comment %} 为了降低第三种情况的影响，在 Raft 算法的设计中，要求每个服务器的 election timeout 都是在某个区间内随机采样的。 {% endcomment %}
{% comment %} 因此，大部分情况下只会有一个 follower 发生超时并转变为 candidate ； {% endcomment %}
{% comment %} 即使有多个 candidate 同时存在，也会在不同时间发生第二次超时，错开重新选举的时间。 {% endcomment %}

{% comment %} ### Log Replication {% endcomment %}

{% comment %} Leader 当选后，会接受 client request （如果有 follower 收到 client request ，则会转交给 leader ）。 {% endcomment %}
{% comment %} 每个 client request 包含一条 state machine 上的命令。 {% endcomment %}

{% comment %} Leader 会将这条命令以及此时的 term 包装成 log entry ，追加到自己的 log 中； {% endcomment %}
{% comment %} 然后向 followers 发送 `AppendEntries` 。 {% endcomment %}

{% comment %} Leader 决定一条 log entry 是否能被安全地执行在 state machine 上； {% endcomment %}
{% comment %} 这样的 log entry 被称为是 "committed" 的。 {% endcomment %}
{% comment %} 当一条 log entry 被大多数服务器复制时，leader 就认为它是 committed ， {% endcomment %}
{% comment %} 并将其中的命令执行到自身的 state machine 上，向 client 返回结果。 {% endcomment %}

{% comment %} 那么，在 leader 执行了 entry 中的命令后，followers 又该在什么时候执行呢？ {% endcomment %}
{% comment %} Leader 会记录 committed log entries 的最高 index ，并把这个 index 作为参数，附加在 `AppendEntries` 中。 {% endcomment %}
{% comment %} 当 follower 收到后，会将小于等于这个 index 、且尚未执行的 entries 依次执行。 {% endcomment %}

{% comment %} ![log entries](/asset/raft/log-entries.png) {% endcomment %}

{% comment %} 在设计上，Raft 保证了一条很重要的性质 **Log Matching Property** {% endcomment %}
{% comment %} - 从两个 logs 中各取一个 entry ，如果它们的 term 和 index 相同，则其中包含的命令也相同（即两个 entries 完全相同） {% endcomment %}
{% comment %} - 从两个 logs 中各取一个 entry ，如果它们相同，则它们之前的所有 entries 都相同 {% endcomment %}

{% comment %} 第一点的证明很容易：term 相同说明这两个 entries 必然是同一个 leader 创建的，而一个 leader 不可能在同一个 index 上多次创建不同的 entry 。 {% endcomment %}
{% comment %} 第二点则是由 `AppendEntries` 的设计保证的：`AppendEntries` 不仅要求 follower 复制 log entries ，还起到了一致性检查的作用。 {% endcomment %}
{% comment %} 具体来说，如果 leader 想对 followers 的 index=i 处插入一个 entry ，则 leader 必须在 `AppendEntries` 中附加 index=i-1 这个 entry 的 term 。 {% endcomment %}
{% comment %} 如果 follower 发现 index=i-1 处的 term 不一致，则拒绝该 `AppendEntries` 。 {% endcomment %}

{% comment %} Log 不一致的情况一般是由于服务器崩溃造成的。Follower 的 log 可能比 leader 少了某些 entries ，也可能多了某些 entries 。 {% endcomment %}
{% comment %} 例如，如果一个服务器崩溃了很长时间，就会缺少一些 entries 。而如果一个服务器曾经在某个 term 是 leader ，在创建几个 entries 后还没来得及调用 `AppendEntries` 就崩溃了，那么它在重启并成为 follower 后，就会比当前的 leader 多出一些 entries 。如下图所示： {% endcomment %}
{% comment %} ![log inconsistence](/asset/raft/log-inconsistence.png) {% endcomment %}

{% comment %} 为了解决 log 不一致的问题，Raft 采取的策略是：用 leader 的 log 去覆盖 followers 的 log 。 {% endcomment %}
{% comment %} 具体来说，leader 会对每个 follower 维护一个 `nextIndex` 值，表示下一次 `AppendEntries` 插入 log entry 的位置。 {% endcomment %}
{% comment %} Leader 刚当选时，会将 `nextIndex` 都初始化为自身 log entries 最大编号 + 1 （对于上图而言，就是 12）。 {% endcomment %}
{% comment %} 然后 leader 会执行以下伪代码： {% endcomment %}
{% comment %} 1. `AppendEntries(nextIndex, ...)` {% endcomment %}
{% comment %}     - 若失败，则 `nextIndex-=1` ，重复第1步 {% endcomment %}
{% comment %}     - 若成功，则跳到第2步 {% endcomment %}
{% comment %} 2. 不断 `AppendEntries(nextIndex, ...)` 并 `nextIndex+=1` ，直到 `nextIndex` 重新回到初始值 {% endcomment %}
{% comment %} 这样，log entries 就只会由 leader 向 followers 单向流动，降低了整个算法的设计复杂性。 {% endcomment %}

{% comment %} 这样，在 leader 当选后的一段时间内，其他服务器的 log 都会被覆盖为 leader 的 log 。 {% endcomment %}
{% comment %} 由于 log entries 只会由 leader 单向流动到其他服务器，所以减少了 Raft 算法的设计复杂度。 {% endcomment %}
{% comment %} 但是，这种设计也要求 leader 在当选时必须包含之前所有 term 的 committed entries ， {% endcomment %}
{% comment %} 否则会导致新的不一致的情况。 {% endcomment %}
{% comment %} 为了解决这个问题，下一节中引入了关于 leader election 的约束条件。 {% endcomment %}

{% comment %} ### Safety {% endcomment %}

{% comment %} ### Follower and Candidate Crashes {% endcomment %}

{% comment %} ### Timing and Availability {% endcomment %}
